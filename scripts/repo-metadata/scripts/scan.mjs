#!/usr/bin/env node
/**
 * scan.mjs â€” æ‰«æä»“åº“ç›®å½•ç»“æ„ï¼Œå¯¹æ¯” SQLite æ•°æ®åº“ï¼ŒæŠ¥å‘Šæ–°å¢/åˆ é™¤/æœªæè¿°æ¡ç›®
 *
 * ç”¨æ³•:
 *   node scan.mjs [--max-depth N] [--update]
 *
 * é€‰é¡¹:
 *   --max-depth N   æœ€å¤§æ‰«ææ·±åº¦ï¼ˆé»˜è®¤: æ— é™åˆ¶ï¼‰
 *   --update        è‡ªåŠ¨æ›´æ–°æ•°æ®åº“ï¼ˆæ·»åŠ æ–°æ¡ç›®ã€ç§»é™¤å·²åˆ é™¤æ¡ç›®ï¼‰
 */
import path from 'node:path';
import { fileURLToPath } from 'node:url';
import {
  depthOf,
  getTrackedPaths,
  openMetadataDb,
  getIgnoreMatchers,
  getNode,
  upsertNode,
  deleteNodeByPath,
  getAllPaths,
  parseFlags,
  shouldIgnore,
} from '../lib/shared.mjs';

const scriptDir = path.dirname(fileURLToPath(import.meta.url));
const repoRoot = path.resolve(scriptDir, '../../../');
const dbPath = path.join(repoRoot, 'docs', 'architecture', 'repo-metadata.db');

async function main() {
  const flags = parseFlags(process.argv.slice(2));
  const maxDepth = flags['max-depth'] ? parseInt(flags['max-depth'], 10) : null;
  const shouldUpdate = flags.update === 'true';

  console.log('ğŸ“ Scanning repository...');

  const db = openMetadataDb(dbPath);

  try {
    const { fileSet, dirSet } = getTrackedPaths(repoRoot);
    const ignoreMatchers = getIgnoreMatchers(db);

    // æ„å»ºç£ç›˜è·¯å¾„ â†’ ç±»å‹æ˜ å°„
    const diskPaths = new Map();
    for (const d of dirSet) {
      if (!shouldIgnore(d, ignoreMatchers)) diskPaths.set(d, 'directory');
    }
    for (const f of fileSet) {
      if (!shouldIgnore(f, ignoreMatchers)) diskPaths.set(f, 'file');
    }

    // åº”ç”¨æ·±åº¦è¿‡æ»¤
    const filteredPaths = maxDepth
      ? new Map([...diskPaths].filter(([p]) => depthOf(p) <= maxDepth))
      : diskPaths;

    const dirCount = [...filteredPaths.values()].filter((t) => t === 'directory').length;
    const fileCount = [...filteredPaths.values()].filter((t) => t === 'file').length;
    console.log(`Found ${dirCount} directories, ${fileCount} files`);

    const existingPaths = getAllPaths(db);

    // å¯¹æ¯”: æ–°å¢ / åˆ é™¤ / æœªæè¿°
    const added = [];
    const undescribed = [];

    for (const [p, type] of filteredPaths) {
      if (!existingPaths.has(p)) {
        added.push({ path: p, type });
      } else {
        const node = getNode(db, p);
        if (node && !node.description) {
          undescribed.push(p);
        }
      }
    }

    const removed = [];
    for (const p of existingPaths) {
      if (!filteredPaths.has(p)) removed.push(p);
    }

    // è¾“å‡ºæŠ¥å‘Š
    if (added.length > 0) {
      console.log(`\nğŸ†• New paths (${added.length}):`);
      for (const { path: p, type } of added.sort((a, b) => a.path.localeCompare(b.path))) {
        console.log(`  + ${p}  (${type})`);
      }
    }

    if (removed.length > 0) {
      console.log(`\nğŸ—‘ï¸  Removed paths (${removed.length}):`);
      for (const p of removed.sort()) console.log(`  - ${p}`);
    }

    if (undescribed.length > 0) {
      console.log(`\nâš ï¸  Undescribed paths (${undescribed.length}):`);
      for (const p of undescribed.sort()) console.log(`  ? ${p}`);
    }

    if (added.length === 0 && removed.length === 0) {
      console.log('\nâœ… Metadata is up to date with filesystem.');
    }

    // æ›´æ–°æ•°æ®åº“
    if (shouldUpdate) {
      const batch = db.transaction(() => {
        for (const { path: p, type } of added) {
          upsertNode(db, p, { type, updatedBy: 'scan' });
        }
        for (const p of removed) {
          deleteNodeByPath(db, p);
        }
      });
      batch();

      console.log(`\nâœ… Updated database: ${added.length} added, ${removed.length} removed`);
    } else if (added.length > 0 || removed.length > 0) {
      console.log('\nğŸ’¡ Run with --update to apply changes to the database');
    }

    console.log(
      `\nSummary: ${added.length} new, ${removed.length} removed, ${undescribed.length} undescribed`,
    );
  } finally {
    db.close();
  }
}

main().catch((err) => {
  console.error(`âŒ Scan failed: ${err.message}`);
  process.exitCode = 1;
});
