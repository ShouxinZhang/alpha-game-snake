import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np

# ==========================================
# 1. åŠ¨æ€è¯¾ç¨‹ç¯å¢ƒä¸ Zero-Padding å¯¹é½æ¨¡å—
# ==========================================
class CurriculumZeroPadWrapper:
    """
    è´Ÿè´£ç®¡ç† 5x5 -> 8x8 -> 11x11 -> 15x15 çš„æ¸è¿›å¼è¯¾ç¨‹ã€‚
    æ— è®ºå½“å‰ç½‘æ ¼å¤šå¤§ï¼Œå§‹ç»ˆå¯¹å¤–è¾“å‡º 15x15 çš„å¼ é‡ï¼Œå®ç°æ¨¡å‹æƒé‡çš„é›¶æ ·æœ¬ (Zero-shot) è¿ç§»ã€‚
    """
    def __init__(self, max_grid=15):
        self.max_grid = max_grid
        self.stages = [5, 8, 11, 15] 
        self.current_stage_idx = 0
        
    @property
    def current_size(self):
        return self.stages[self.current_stage_idx]
        
    def pad_state(self, state):
        """
        æ ¸å¿ƒæœºåˆ¶ï¼šå°†è¾ƒå°å°ºå¯¸(å¦‚5x5)çš„ç½‘æ ¼å±…ä¸­ï¼Œå¤–å›´å¡«å…… -1.0 (ä»£è¡¨ä¸å¯è·¨è¶Šçš„å¢™å£)
        è¾“å…¥ state shape: (Channels, N, N) -> è¾“å‡º shape: (Channels, 15, 15)
        """
        N = self.current_size
        if N == self.max_grid:
            return torch.tensor(state, dtype=torch.float32)
            
        pad_total = self.max_grid - N
        pad_lt = pad_total // 2       # å·¦/ä¸Šæ–¹å¡«å……é‡
        pad_rb = pad_total - pad_lt   # å³/ä¸‹æ–¹å¡«å……é‡
        
        # F.pad padding æ ¼å¼: (å·¦, å³, ä¸Š, ä¸‹)
        padded = F.pad(
            torch.tensor(state, dtype=torch.float32), 
            (pad_lt, pad_rb, pad_lt, pad_rb), 
            mode='constant', value=-1.0
        )
        return padded

    def step_curriculum(self, recent_avg_length):
        """è¯„ä¼°æ˜¯å¦æ»¡è¶³æ™‹çº§ä¸‹ä¸€é˜¶æ®µè¯¾ç¨‹çš„æ¡ä»¶"""
        capacity = self.current_size ** 2
        # æ™‹çº§æ¡ä»¶ï¼šæœ€è¿‘å±€å¹³å‡è›‡é•¿è¶…è¿‡å½“å‰åœºåœ°å®¹é‡çš„ 60%
        if recent_avg_length >= capacity * 0.6 and self.current_stage_idx < len(self.stages) - 1:
            self.current_stage_idx += 1
            print(f"ğŸ”¥ è¯¾ç¨‹å‡çº§ï¼ç¯å¢ƒæ‰©å®¹è‡³: {self.current_size}x{self.current_size}")
            return True
        return False

# ==========================================
# 2. è§†è§‰ Transformer (ViT) ä¸ MAE éª¨å¹²ç½‘ç»œ
# ==========================================
class ViT_MAE_Encoder(nn.Module):
    """
    è§†è§‰ Transformerï¼šå…·å¤‡å…¨å±€è§†é‡ï¼Œèƒ½å¤Ÿåœ¨é•¿ç¨‹ä¾èµ–ä¸‹åˆ¤æ–­è›‡å¤´å’Œè›‡å°¾çš„å…³ç³»ã€‚
    æ”¯æŒåœ¨æ— ç›‘ç£è®­ç»ƒæ—¶éšæœºæ©ç›– (Mask) ç”»é¢ä¸­çš„éƒ¨åˆ† Patchã€‚
    """
    def __init__(self, in_channels=3, max_grid=15, patch_size=3, embed_dim=128):
        super().__init__()
        self.patch_size = patch_size
        self.num_patches = (max_grid // patch_size) ** 2  # 15/3=5 -> å…± 25 ä¸ª Patch
        
        # å›¾å—åµŒå…¥ (Patch Embedding)
        self.patch_embed = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)
        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))
        self.pos_embed = nn.Parameter(torch.randn(1, self.num_patches + 1, embed_dim))
        
        # æ©ç å ä½ç¬¦ (ä»£æ›¿è¢« MAE é®ç›–æ‰çš„åŒºåŸŸ)
        self.mask_token = nn.Parameter(torch.zeros(1, 1, embed_dim))
        
        # Transformer ç¼–ç å™¨
        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=4, dim_feedforward=256, batch_first=True)
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=3)

    def forward(self, x, mask_ratio=0.0):
        B = x.size(0)
        # å°ºå¯¸å˜æ¢: (B, C, 15, 15) -> (B, embed_dim, 5, 5) -> (B, 25, embed_dim)
        patches = self.patch_embed(x).flatten(2).transpose(1, 2)
        
        mask_indices = None
        # æ— ç›‘ç£ MAE æ©ç›–é€»è¾‘ (ä»…åœ¨æ›´æ–°ç½‘ç»œæ—¶è§¦å‘)
        if mask_ratio > 0:
            num_mask = int(self.num_patches * mask_ratio)
            # éšæœºç”Ÿæˆæ¯ä¸ªæ ·æœ¬è¢«é®ç›–çš„ Patch ç´¢å¼•
            noise = torch.rand(B, self.num_patches, device=x.device)
            mask_indices = torch.argsort(noise, dim=1)[:, :num_mask]
            
            # å°†é€‰ä¸­çš„ Patch æ›¿æ¢ä¸ºå¯å­¦ä¹ çš„ Mask Token
            mask_tokens = self.mask_token.expand(B, num_mask, -1)
            for i in range(B):
                patches[i, mask_indices[i]] = mask_tokens[i]
                
        # æ‹¼æ¥ CLS Token ä¸ä½ç½®ç¼–ç 
        cls_tokens = self.cls_token.expand(B, -1, -1)
        x_seq = torch.cat((cls_tokens, patches), dim=1) + self.pos_embed
        
        # å…¨å±€è‡ªæ³¨æ„åŠ›è®¡ç®—
        features = self.transformer(x_seq)
        cls_feat = features[:, 0]       # å…¨å±€ç‰¹å¾ (äº¤ä»˜ç»™ Actor-Critic å’Œ ICM)
        patch_feats = features[:, 1:]   # å±€éƒ¨å›¾å—ç‰¹å¾ (äº¤ä»˜ç»™ MAE è§£ç å™¨é‡å»ºåƒç´ )
        
        return cls_feat, patch_feats, mask_indices

# ==========================================
# 3. æ ¸å¿ƒæ™ºèƒ½ä½“ä¸å†…åœ¨å¥½å¥‡å¿ƒæ¨¡å— (ICM)
# ==========================================
class ViTSnakeAgent(nn.Module):
    def __init__(self, action_dim=4, in_channels=3, patch_size=3, embed_dim=128):
        super().__init__()
        self.encoder = ViT_MAE_Encoder(in_channels, max_grid=15, patch_size=patch_size, embed_dim=embed_dim)
        
        # 1. PPO Actor-Critic ç½‘ç»œå¤´
        self.actor = nn.Sequential(nn.Linear(embed_dim, 64), nn.ReLU(), nn.Linear(64, action_dim))
        self.critic = nn.Sequential(nn.Linear(embed_dim, 64), nn.ReLU(), nn.Linear(64, 1))
        
        # 2. MAE è§£ç å™¨ (å°†è¢«æ‰“ç çš„ç‰¹å¾è¿˜åŸä¸ºåŸå§‹ 3é€šé“ çš„ Patch åƒç´ )
        patch_dim = in_channels * patch_size * patch_size
        self.mae_decoder = nn.Sequential(
            nn.Linear(embed_dim, 128), nn.ReLU(), nn.Linear(128, patch_dim)
        )
        
        # 3. ICM åŠ¨åŠ›å­¦æ¨¡å‹ (å¥½å¥‡å¿ƒé©±åŠ¨)
        # å‰å‘é¢„æµ‹: åŸºäº s_t å’Œ a_tï¼Œé¢„æµ‹ s_{t+1} (è¡¡é‡æ¢ç´¢çš„æ–°é¢–åº¦)
        self.icm_forward = nn.Sequential(
            nn.Linear(embed_dim + action_dim, 128), nn.ReLU(), nn.Linear(128, embed_dim)
        )
        # é€†å‘é¢„æµ‹: åŸºäº s_t å’Œ s_{t+1}ï¼Œé¢„æµ‹ a_t (ç¡®ä¿ç‰¹å¾ç©ºé—´åªæå–å—åŠ¨ä½œå½±å“çš„åŠ¨æ€ç‰¹å¾)
        self.icm_inverse = nn.Sequential(
            nn.Linear(embed_dim * 2, 128), nn.ReLU(), nn.Linear(128, action_dim)
        )

    def get_action(self, state):
        """ä¸æ¸¸æˆç¯å¢ƒäº¤äº’æ—¶è°ƒç”¨ (è§†é‡å®Œå…¨å¼€å¯ï¼Œæ—  Mask)"""
        cls_feat, _, _ = self.encoder(state, mask_ratio=0.0)
        logits = self.actor(cls_feat)
        value = self.critic(cls_feat)
        
        dist = torch.distributions.Categorical(logits=logits)
        action = dist.sample()
        return action, dist.log_prob(action), value, cls_feat

    def compute_intrinsic_reward(self, cls_feat, next_cls_feat, action):
        """åœ¨ç¯å¢ƒäº¤äº’(Rollout)æ—¶è°ƒç”¨ï¼šé¢„æµ‹è¯¯å·®è¶Šå¤§ï¼Œç»™çš„æ¢ç´¢å¥½å¥‡å¿ƒå¥–åŠ±è¶Šé«˜"""
        action_onehot = F.one_hot(action, num_classes=4).float()
        pred_next_feat = self.icm_forward(torch.cat([cls_feat, action_onehot], dim=-1))
        
        int_reward = F.mse_loss(pred_next_feat, next_cls_feat.detach(), reduction='none').mean(dim=-1)
        return int_reward

# ==========================================
# 4. å¤šç›®æ ‡è”åˆæŸå¤±è®¡ç®—å¼•æ“ (Training Engine)
# ==========================================
def compute_joint_loss(agent, batch, clip_ratio=0.2, mae_weight=0.5, icm_weight=0.1):
    """
    æ›¿æ¢æ ‡å‡† PPO çš„ loss è®¡ç®—ï¼Œèåˆ RLç›‘ç£ + MAEè‡ªç›‘ç£ + ICMå¥½å¥‡å¿ƒ
    batch: åŒ…å«å·²è½¬æ¢ä¸º Tensor ä¸” padding åˆ° 15x15 çš„æ•°æ®
    """
    states, actions, returns, advantages, old_log_probs, next_states = batch
    B = states.shape[0]
    patch_size = agent.encoder.patch_size
    
    # --- 1. ViT å‰å‘ä¼ æ’­ (æ¿€è¿›åœ°æ–½åŠ  40% Maskï¼Œé€¼è¿« Transformer ç†è§£ç‰©ç†è§„å¾‹) ---
    cls_feat, patch_feats, mask_indices = agent.encoder(states, mask_ratio=0.40)
    with torch.no_grad(): # ä¸‹ä¸€ä¸ªçŠ¶æ€ä¸éœ€è¦è®¡ç®—æ¢¯åº¦ï¼Œä¹Ÿä¸éœ€è¦æ‰“æ©ç 
        next_cls_feat, _, _ = agent.encoder(next_states, mask_ratio=0.0)
    
    # --- 2. PPO Actor-Critic æŸå¤± ---
    logits = agent.actor(cls_feat)
    values = agent.critic(cls_feat).squeeze(-1)
    dist = torch.distributions.Categorical(logits=logits)
    new_log_probs = dist.log_prob(actions)
    entropy = dist.entropy().mean()
    
    ratio = torch.exp(new_log_probs - old_log_probs)
    surr1 = ratio * advantages
    surr2 = torch.clamp(ratio, 1.0 - clip_ratio, 1.0 + clip_ratio) * advantages
    actor_loss = -torch.min(surr1, surr2).mean()
    critic_loss = F.mse_loss(values, returns)
    ppo_loss = actor_loss + 0.5 * critic_loss - 0.01 * entropy
    
    # --- 3. MAE æ— ç›‘ç£é‡å»ºæŸå¤± ---
    pred_patches = agent.mae_decoder(patch_feats) # (B, 25, patch_dim)
    # åˆ©ç”¨ unfold æå–çœŸå®çš„åŸå§‹å›¾åƒ Patch ä½œä¸º Ground Truth: (B, C, 15, 15) -> (B, 25, C*P*P)
    target_patches = F.unfold(states, kernel_size=patch_size, stride=patch_size).transpose(1, 2)
    
    mae_loss = 0.0
    # ç²¾é«“ï¼šåªè®¡ç®—é‚£ 40% è¢«è’™ä½åŒºåŸŸçš„åƒç´ é‡å»ºè¯¯å·® MSE
    for i in range(B):
        masked_preds = pred_patches[i, mask_indices[i]]
        masked_targets = target_patches[i, mask_indices[i]]
        mae_loss += F.mse_loss(masked_preds, masked_targets)
    mae_loss /= max(B, 1)
    
    # --- 4. ICM å†…éƒ¨å¥½å¥‡å¿ƒåŠ¨åŠ›å­¦æŸå¤± ---
    action_onehot = F.one_hot(actions, num_classes=4).float()
    pred_next_feat = agent.icm_forward(torch.cat([cls_feat, action_onehot], dim=-1))
    pred_action_logits = agent.icm_inverse(torch.cat([cls_feat, next_cls_feat], dim=-1))
    
    icm_forward_loss = F.mse_loss(pred_next_feat, next_cls_feat)
    icm_inverse_loss = F.cross_entropy(pred_action_logits, actions)
    icm_loss = icm_forward_loss + icm_inverse_loss
    
    # --- 5. å¤šç›®æ ‡æ€»æŸå¤±èåˆä¸åå‘ä¼ æ’­ ---
    # æç¤ºï¼šéšç€è¯¾ç¨‹å‡çº§åˆ° 15x15 åæœŸï¼Œå¯ä»¥æ…¢æ…¢é€šè¿‡ä»£ç è¡°å‡ icm_weight é¿å…æ— æ•ˆæ¢ç´¢
    total_loss = ppo_loss + mae_weight * mae_loss + icm_weight * icm_loss
    
    loss_metrics = {"ppo_loss": ppo_loss.item(), "mae_loss": mae_loss.item(), "icm_loss": icm_loss.item()}
    return total_loss, loss_metrics